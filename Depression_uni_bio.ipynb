{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten,Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIOGroupFileNames = os.listdir('data/new_dataset/bio')\n",
    "UNIGroupFileNames = os.listdir('data/new_dataset/uni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for fileName in BIOGroupFileNames:\n",
    "    df = pd.read_csv('data/new_dataset/bio/'+str(fileName))\n",
    "    dates = df['date'].unique()\n",
    "    activityLevelsPerDay = []\n",
    "    for date in dates:\n",
    "        if len(df[df['date']==date]) == 1440:\n",
    "            temp = pd.DataFrame(df[df['date']==date]).drop(columns=['timestamp','date'])\n",
    "            activityLevelsPerDay.append(temp)\n",
    "    for dailyActivityLevel in activityLevelsPerDay:\n",
    "        activityVector = np.array(dailyActivityLevel[\"activity\"])\n",
    "        if len(activityVector) == 1440:\n",
    "            X.append(activityVector)\n",
    "            y.append(0) #1 means bio\n",
    "\n",
    "\n",
    "for fileName in UNIGroupFileNames:\n",
    "    df = pd.read_csv('data/new_dataset/uni/'+str(fileName))\n",
    "    dates = df['date'].unique()\n",
    "    activityLevelsPerDay = []\n",
    "    for date in dates:\n",
    "        if len(df[df['date']==date]) == 1440:\n",
    "            temp = pd.DataFrame(df[df['date']==date]).drop(columns=['timestamp','date'])\n",
    "            activityLevelsPerDay.append(temp)\n",
    "    for dailyActivityLevel in activityLevelsPerDay:\n",
    "        activityVector = np.array(dailyActivityLevel[\"activity\"])\n",
    "        if len(activityVector) == 1440:\n",
    "            X.append(activityVector)\n",
    "            y.append(1) #0 means uni\n",
    "\n",
    "combinedDict = list(zip(X, y))\n",
    "random.shuffle(combinedDict)\n",
    "X[:], y[:] = zip(*combinedDict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "seed = 7\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "accuracy_scores = []\n",
    "prec_scores = []\n",
    "rec_scores = []\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(359, 1, 1440) (359,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "acc: 0.62%\n",
      "recall_m: 0.79%\n",
      "precision_m: 0.67%\n",
      "f1_m: 0.73%\n",
      "\n",
      "\n",
      "acc: 0.35%\n",
      "recall_m: 0.00%\n",
      "precision_m: 0.00%\n",
      "f1_m: 0.00%\n",
      "\n",
      "\n",
      "acc: 0.61%\n",
      "recall_m: 0.92%\n",
      "precision_m: 0.64%\n",
      "f1_m: 0.75%\n",
      "\n",
      "\n",
      "acc: 0.61%\n",
      "recall_m: 0.85%\n",
      "precision_m: 0.65%\n",
      "f1_m: 0.73%\n",
      "\n",
      "\n",
      "acc: 0.68%\n",
      "recall_m: 1.00%\n",
      "precision_m: 0.67%\n",
      "f1_m: 0.80%\n",
      "\n",
      "\n",
      "평균 AUC: 0.5712923664020583 | 평균 오차범위: 0.11487902029785878\n",
      "평균 rec: 0.7117140487420699 | 평균 오차범위: 0.3627118455573027\n",
      "평균 pre: 0.527261621182654 | 평균 오차범위: 0.26386415782817785\n",
      "평균 f1: 0.6016172935360229 | 평균 오차범위: 0.3018771515961794\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(X, y):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(1, 1440), return_sequences=True))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', recall_m, precision_m, f1_m])\n",
    "\n",
    "    model.fit(X[train], y[train], epochs=20, batch_size=128, verbose=0)\n",
    "    scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[2], scores[2]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[3], scores[3]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[4], scores[4]))\n",
    "    print(\"\\n\")\n",
    "    accuracy_scores.append(scores[1])\n",
    "    rec_scores.append(scores[2])\n",
    "    prec_scores.append(scores[3])\n",
    "    f1_scores.append(scores[4])\n",
    "\n",
    "\n",
    "print('평균 AUC:', np.mean(accuracy_scores), '| 평균 오차범위:', np.std(accuracy_scores))\n",
    "print('평균 rec:',np.mean(rec_scores), '| 평균 오차범위:', np.std(rec_scores))\n",
    "print('평균 pre:',np.mean(prec_scores), '| 평균 오차범위:', np.std(prec_scores))\n",
    "print('평균 f1:',np.mean(f1_scores), '| 평균 오차범위:', np.std(f1_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
